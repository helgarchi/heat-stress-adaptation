{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92a70fc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load the geopackage files\n",
    "buildings = gpd.read_file(\"data/buildings_saocristovao.gpkg\")\n",
    "#addresses = gpd.read_file(\"addresses_mhi.gpkg\")\n",
    "addresses_all=gpd.read_file(\"data/enderecos.gpkg\")\n",
    "favelas=gpd.read_file(\"data/favela_valid.gpkg\")\n",
    "\n",
    "\n",
    "# Convert all column names in buildings and addresses to lowercase\n",
    "buildings.columns = [col.lower() for col in buildings.columns]\n",
    "#addresses.columns = [col.lower() for col in addresses.columns]\n",
    "addresses_all.columns = [col.lower() for col in addresses_all.columns]\n",
    "\n",
    "# Filter addresses based on cod_uso\n",
    "addresses_filtered = addresses_all[addresses_all['cod_uso'].isin([2, 4])]\n",
    "\n",
    "addresses_filtered_nonres = addresses_all[~addresses_all['cod_uso'].isin([2, 4])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479451b7",
   "metadata": {},
   "source": [
    "First we select non-residential buildings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80f07450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building-based matches: 3618\n",
      " addressed based matches: 2321\n",
      "Total unmatched addresses in loop: 246, should be equal with total of unmatched indexes: 246\n"
     ]
    }
   ],
   "source": [
    "def spatial_join1(buildings,addresses_filtered_nonres):\n",
    "    # Reset index for buildings table to ensure every row has an index\n",
    "    buildings = buildings.reset_index(drop=True)\n",
    "    \n",
    "    # Add a suffix to address columns to avoid name conflicts, but not to the geometry column\n",
    "    addresses_filtered = addresses_filtered_nonres.rename(columns={col: f\"{col}_y\" for col in addresses_filtered_nonres.columns if col in buildings.columns and col != 'geometry'})\n",
    "    \n",
    "    # Create a buffer around addresses\n",
    "    # Re-project to a projected CRS\n",
    "    projected_crs = addresses_filtered.to_crs(epsg=3395)  # Using EPSG:3395 (World Mercator) as an example of a projected CRS\n",
    "    addresses_buffered = projected_crs.copy()\n",
    "    addresses_buffered['geometry'] = addresses_buffered.geometry.buffer(5)\n",
    "    # Re-project back to the original CRS\n",
    "    addresses_buffered = addresses_buffered.to_crs(addresses_filtered.crs)\n",
    "    \n",
    "    # Save the original building geometry\n",
    "    buildings['savegeom'] = buildings.geometry\n",
    "\n",
    "    # Spatial join with buildings\n",
    "    joined = gpd.sjoin(addresses_buffered, buildings, how='left', predicate='intersects')\n",
    "    \n",
    "    # Counter for unmatched addresses\n",
    "    unmatched_count = 0\n",
    "    unmatched_count_loop=0\n",
    "    \n",
    "    # Check for missing index_right values\n",
    "    if joined['index_right'].isnull().any():\n",
    "        unmatched_count += joined['index_right'].isnull().sum()\n",
    "    \n",
    "    # Calculate intersection areas\n",
    "    def calculate_intersection_area(row):\n",
    "        building_match = buildings.loc[buildings.index == row['index_right']]\n",
    "        if not building_match.empty:\n",
    "            return row['geometry'].intersection(building_match.geometry.iloc[0]).area\n",
    "        else:\n",
    "            nonlocal unmatched_count_loop\n",
    "            unmatched_count_loop += 1\n",
    "            return 0\n",
    "\n",
    "    joined['intersection_area'] = joined.apply(lambda row: calculate_intersection_area(row), axis=1)\n",
    "\n",
    "    # Fill NaN values in np column with 0 and convert to integer\n",
    "    joined['np'] = joined['np'].fillna(0).astype(int)\n",
    "    \n",
    "    # First group by building index\n",
    "    grouped_by_building = joined.groupby(joined.index_right)\n",
    "\n",
    "    # Create a list to store the selected matches for each building\n",
    "    initial_matches_list = []\n",
    "\n",
    "    # For each building, select the matching address based on criteria\n",
    "    for idx, group in grouped_by_building:\n",
    "        if any(group['np'] > 0):\n",
    "            # If there are np values greater than 0, filter out np == 0\n",
    "            group = group[group['np'] != 0]\n",
    "        if not group.empty:\n",
    "            # Sort matches by intersection area in descending order\n",
    "            group = group.sort_values(by='intersection_area', ascending=False)\n",
    "            first_match = group.iloc[0]\n",
    "            initial_matches_list.append(first_match)\n",
    "\n",
    "    # Convert the list to a GeoDataFrame\n",
    "    initial_matches = gpd.GeoDataFrame(initial_matches_list, columns=joined.columns, crs=buildings.crs)\n",
    "    \n",
    "    print(f\"building-based matches: {initial_matches.shape[0]}\")\n",
    "\n",
    "    # Now group by the original address index to select the best match for each address\n",
    "    grouped_by_address = initial_matches.groupby(initial_matches.index)\n",
    "\n",
    "    # Create a list to store the final selected matches\n",
    "    final_matches_list = []\n",
    "\n",
    "    # For each address, select the matching building with the greatest intersection area\n",
    "    for idx, group in grouped_by_address:\n",
    "        # Sort matches by intersection area in descending order\n",
    "        group = group.sort_values(by='intersection_area', ascending=False)\n",
    "        first_match = group.iloc[0]\n",
    "        final_matches_list.append(first_match)\n",
    "\n",
    "    # Convert the list to a GeoDataFrame\n",
    "    final_matches = gpd.GeoDataFrame(final_matches_list, columns=initial_matches.columns, crs=buildings.crs)\n",
    "\n",
    "    print(f\" addressed based matches: {final_matches.shape[0]}\")\n",
    "    \n",
    "\n",
    "    print(f\"Total unmatched addresses in loop: {unmatched_count_loop}, should be equal with total of unmatched indexes: {unmatched_count}\")\n",
    "    \n",
    "    #print(f\"all matches after adding additional buildings based on cod_unico: {all_matches.shape[0]}\")\n",
    "    return final_matches\n",
    "\n",
    "# Perform the spatial join\n",
    "selected_matches_nonres = spatial_join1(buildings, addresses_filtered_nonres)\n",
    "\n",
    "# Save the selected matches to a new geopackage file\n",
    "selected_matches_nonres.to_file(\"output/selected_matches_all_nonres.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9526d7f4",
   "metadata": {},
   "source": [
    "Then we select additional buildings within cod lote, subtracting those that match with non-residential buildings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "575f6273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building-based matches: 5503\n",
      " addressed based matches: 3401\n",
      "Total unmatched addresses in loop: 69, should be equal with total of unmatched indexes: 69\n",
      "all matches after adding additional buildings based on cod_lote: 18547\n"
     ]
    }
   ],
   "source": [
    "def spatial_join(buildings, addresses_filtered):\n",
    "    # Reset index for buildings table to ensure every row has an index\n",
    "    buildings = buildings.reset_index(drop=True)\n",
    "    \n",
    "    # Add a suffix to address columns to avoid name conflicts, but not to the geometry column\n",
    "    addresses_filtered = addresses_filtered.rename(columns={col: f\"{col}_y\" for col in addresses_filtered.columns if col in buildings.columns and col != 'geometry'})\n",
    "    \n",
    "    # Create a buffer around addresses\n",
    "    # Re-project to a projected CRS\n",
    "    projected_crs = addresses_filtered.to_crs(epsg=3395)  # Using EPSG:3395 (World Mercator) as an example of a projected CRS\n",
    "    addresses_buffered = projected_crs.copy()\n",
    "    addresses_buffered['geometry'] = addresses_buffered.geometry.buffer(5)\n",
    "    # Re-project back to the original CRS\n",
    "    addresses_buffered = addresses_buffered.to_crs(addresses_filtered.crs)\n",
    "    \n",
    "    # Save the original building geometry\n",
    "    buildings['savegeom'] = buildings.geometry\n",
    "\n",
    "    # Spatial join with buildings\n",
    "    joined = gpd.sjoin(addresses_buffered, buildings, how='left', predicate='intersects')\n",
    "    \n",
    "    # Counter for unmatched addresses\n",
    "    unmatched_count = 0\n",
    "    unmatched_count_loop=0\n",
    "    \n",
    "    # Check for missing index_right values\n",
    "    if joined['index_right'].isnull().any():\n",
    "        unmatched_count += joined['index_right'].isnull().sum()\n",
    "    \n",
    "    # Calculate intersection areas\n",
    "    def calculate_intersection_area(row):\n",
    "        building_match = buildings.loc[buildings.index == row['index_right']]\n",
    "        if not building_match.empty:\n",
    "            return row['geometry'].intersection(building_match.geometry.iloc[0]).area\n",
    "        else:\n",
    "            nonlocal unmatched_count_loop\n",
    "            unmatched_count_loop += 1\n",
    "            return 0\n",
    "\n",
    "    joined['intersection_area'] = joined.apply(lambda row: calculate_intersection_area(row), axis=1)\n",
    "\n",
    "    # Fill NaN values in np column with 0 and convert to integer\n",
    "    joined['np'] = joined['np'].fillna(0).astype(int)\n",
    "    \n",
    "    # First group by building index\n",
    "    grouped_by_building = joined.groupby(joined.index_right)\n",
    "\n",
    "    # Create a list to store the selected matches for each building\n",
    "    initial_matches_list = []\n",
    "\n",
    "    # For each building, select the matching address based on criteria\n",
    "    for idx, group in grouped_by_building:\n",
    "        if any(group['np'] > 0):\n",
    "            # If there are np values greater than 0, filter out np == 0\n",
    "            group = group[group['np'] != 0]\n",
    "        if not group.empty:\n",
    "            # Sort matches by intersection area in descending order\n",
    "            group = group.sort_values(by='intersection_area', ascending=False)\n",
    "            first_match = group.iloc[0]\n",
    "            initial_matches_list.append(first_match)\n",
    "\n",
    "    # Convert the list to a GeoDataFrame\n",
    "    initial_matches = gpd.GeoDataFrame(initial_matches_list, columns=joined.columns, crs=buildings.crs)\n",
    "    \n",
    "    print(f\"building-based matches: {initial_matches.shape[0]}\")\n",
    "\n",
    "    # Now group by the original address index to select the best match for each address\n",
    "    grouped_by_address = initial_matches.groupby(initial_matches.index)\n",
    "\n",
    "    # Create a list to store the final selected matches\n",
    "    final_matches_list = []\n",
    "\n",
    "    # For each address, select the matching building with the greatest intersection area\n",
    "    for idx, group in grouped_by_address:\n",
    "        # Sort matches by intersection area in descending order\n",
    "        group = group.sort_values(by='intersection_area', ascending=False)\n",
    "        first_match = group.iloc[0]\n",
    "        final_matches_list.append(first_match)\n",
    "\n",
    "    # Convert the list to a GeoDataFrame\n",
    "    final_matches = gpd.GeoDataFrame(final_matches_list, columns=initial_matches.columns, crs=buildings.crs)\n",
    "\n",
    "    print(f\" addressed based matches: {final_matches.shape[0]}\")\n",
    "    \n",
    "    \n",
    "    # Identify unique cod_lote values in final_matches\n",
    "    unique_cod_lote = final_matches['cod_lote'].unique()\n",
    "    \n",
    "    # Filter buildings to include all rows with those cod_lote values and exclude those already in final_matches\n",
    "    additional_buildings = buildings[\n",
    "        (buildings['cod_lote'].isin(unique_cod_lote)) & \n",
    "        (~buildings.index.isin(final_matches['index_right'])) &\n",
    "        (~buildings.index.isin(selected_matches_nonres['index_right']))\n",
    "    ]\n",
    "    \n",
    "    #additional_buildings= additional_buildings.loc[additional_buildings['shape__area']<300]\n",
    "\n",
    "    # Select the address-related columns from addresses_filtered after renaming and cod_lote\n",
    "    address_columns = list(addresses_filtered.columns) + ['cod_lote']\n",
    "    \n",
    "    # Drop unnecessary columns from final_matches except for address columns and cod_lote\n",
    "    final_matches_a = final_matches[address_columns]\n",
    "    \n",
    "    # Merge additional_buildings with final_matches to copy address columns\n",
    "    additional_buildings = additional_buildings.merge(final_matches_a, on='cod_lote', how='left', suffixes=('', '_y'))\n",
    "\n",
    "    # Concatenate final_matches and additional_buildings\n",
    "    all_matches = pd.concat([final_matches, additional_buildings])\n",
    "    \n",
    "    # Drop the original 'geometry' column which contains address geometries\n",
    "    all_matches.drop(columns=['geometry', 'geometry_y'], inplace=True)\n",
    "    \n",
    "    # Set the geometry to the original building geometries and set CRS to the original buildings CRS\n",
    "    all_matches = all_matches.set_geometry('savegeom').set_crs(buildings.crs, allow_override=True)\n",
    "    \n",
    "    # Rename 'savegeom' to 'geometry' to match expected output\n",
    "    all_matches.rename_geometry('geometry', inplace=True)\n",
    "\n",
    "    print(f\"Total unmatched addresses in loop: {unmatched_count_loop}, should be equal with total of unmatched indexes: {unmatched_count}\")\n",
    "    \n",
    "    print(f\"all matches after adding additional buildings based on cod_lote: {all_matches.shape[0]}\")\n",
    "    return all_matches\n",
    "\n",
    "# Perform the spatial join\n",
    "selected_matches = spatial_join(buildings, addresses_filtered)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206db846",
   "metadata": {},
   "source": [
    "Assigning typology labels based on conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2f62353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_typology(selected_matches):\n",
    "    # Define conditions and corresponding typology values\n",
    "    conditions = [\n",
    "        (selected_matches['cod_tipologia'] == 1) & (selected_matches['num_pavimentos'] <= 2),\n",
    "        (selected_matches['cod_tipologia'] == 1) & (selected_matches['num_pavimentos'] > 2),\n",
    "        (selected_matches['cod_tipologia'] == 5) & (selected_matches['num_pavimentos'] <= 2),\n",
    "        (selected_matches['cod_tipologia'] == 5) & (selected_matches['num_pavimentos'] > 2),\n",
    "        (selected_matches['cod_tipologia'] == 2),\n",
    "        (selected_matches['cod_tipologia'] == 4),\n",
    "        (selected_matches['cod_tipologia'] == 3) & (selected_matches['num_pavimentos'] <= 4),\n",
    "        (selected_matches['cod_tipologia'] == 3) & (selected_matches['num_pavimentos'] > 4),\n",
    "        (selected_matches['cod_tipologia'] == 6) & (selected_matches['num_pavimentos'] <= 4),\n",
    "        (selected_matches['cod_tipologia'] == 6) & (selected_matches['num_pavimentos'] > 4)  \n",
    "    ]\n",
    "    \n",
    "    # Corresponding typology values\n",
    "    typology_values = [\n",
    "        'house_low',\n",
    "        'house_high',\n",
    "        'house_low',\n",
    "        'house_high',\n",
    "        'sobrado',\n",
    "        'villa',\n",
    "        'apartment_building_low',\n",
    "        'apartment_building_high',\n",
    "        'apartment_building_low',\n",
    "        'apartment_building_high'\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    # Assign typology based on conditions\n",
    "    selected_matches['typology'] = np.select(conditions, typology_values, default=np.nan)\n",
    "\n",
    "    return selected_matches\n",
    "\n",
    "# Assuming selected_matches is already defined as a GeoDataFrame\n",
    "selected_matches = assign_typology(selected_matches)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a83e9fe",
   "metadata": {},
   "source": [
    "Count of selected matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec45c445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18547"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c2c4ed",
   "metadata": {},
   "source": [
    "Merging building polygons into \"complete\" buildings by cod_unico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baa0fc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "def merge_geometries_by_cod_unico(selected_matches):\n",
    "    # Function to merge geometries and keep the first row's data\n",
    "    def merge_group(group):\n",
    "        # Merge geometries within the group\n",
    "        merged_geometry = unary_union(group.geometry)\n",
    "        \n",
    "        # Copy the first row's data, then update the geometry with the merged geometry\n",
    "        first_row = group.iloc[0].copy()\n",
    "        first_row.geometry = merged_geometry\n",
    "        \n",
    "        return first_row\n",
    "    \n",
    "    # Group by 'cod_unico' and apply the merge function, excluding the grouping columns\n",
    "    merged_matches = selected_matches.groupby('cod_unico').apply(merge_group, include_groups=False)\n",
    "    \n",
    "    return merged_matches\n",
    "\n",
    "# Assuming selected_matches is already defined as a GeoDataFrame\n",
    "merged_matches = merge_geometries_by_cod_unico(selected_matches)\n",
    "\n",
    "# Now 'merged_matches' has merged geometries and retains the first row's data for each 'cod_unico'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c1ed971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8905"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_matches.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6342b0",
   "metadata": {},
   "source": [
    "Adding favela buildings (those that are within favela boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd56b890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "def filter_favela_buildings(buildings, favelas):\n",
    "    # Perform the spatial join to find intersections\n",
    "    favela_buildings = gpd.sjoin(buildings, favelas, how='inner', predicate='intersects')\n",
    "    \n",
    "    # Drop the columns that were added from the favelas GeoDataFrame\n",
    "    columns_to_drop = favela_buildings.columns.difference(buildings.columns).to_list()\n",
    "    favela_buildings = favela_buildings.drop(columns=columns_to_drop)\n",
    "    \n",
    "    return favela_buildings\n",
    "\n",
    "# 2. Add the column 'tipo' with value 'favela'\n",
    "def add_tipo_column(favela_buildings):\n",
    "    favela_buildings['tipo'] = 'favela'\n",
    "    return favela_buildings\n",
    "\n",
    "# 4. Assign typology based on 'altura'\n",
    "def assign_typology_based_on_altura(favela_buildings):\n",
    "    favela_buildings['typology'] = favela_buildings['altura'].apply(lambda x: 'house_low' if x < 6.9 else 'house_high')\n",
    "    return favela_buildings\n",
    "\n",
    "# 5. Filter merged_matches to exclude specific 'tipo' values\n",
    "def filter_merged_matches(merged_matches):\n",
    "    excluded_tipos = [\n",
    "        'A102 - EDIFICACAO_FAVELA', 'A103 - PROJECAO_1_FAVELA', \n",
    "        'A104 - PROJECAO_2_FAVELA', 'A105 - PROJECAO_3_FAVELA', \n",
    "        'A113 - CONSTRUCAO_FAVELA', 'A114 - RUINA_FAVELA'\n",
    "    ]\n",
    "    filtered_matches = merged_matches[~merged_matches['tipo'].isin(excluded_tipos)]\n",
    "    return filtered_matches\n",
    "\n",
    "# 6. Concatenate favela_buildings with merged_matches\n",
    "def concatenate_dataframes(favela_buildings, merged_matches):\n",
    "    concatenated_df = pd.concat([favela_buildings, merged_matches], ignore_index=True)\n",
    "    return concatenated_df\n",
    "\n",
    "# Assuming 'buildings' and 'favelas' are your GeoDataFrames, and 'merged_matches' is defined\n",
    "\n",
    "# Step 1: Filter favela buildings\n",
    "favela_buildings = filter_favela_buildings(buildings, favelas)\n",
    "\n",
    "# Step 2: Add 'tipo' column with value 'favela'\n",
    "favela_buildings = add_tipo_column(favela_buildings)\n",
    "\n",
    "# Step 3: Merge geometries by 'cod_unico'\n",
    "favela_buildings = merge_geometries_by_cod_unico(favela_buildings)\n",
    "\n",
    "# Step 4: Assign typology based on 'altura'\n",
    "favela_buildings = assign_typology_based_on_altura(favela_buildings)\n",
    "\n",
    "# Step 5: Filter merged_matches to exclude specific 'tipo' values\n",
    "filtered_merged_matches = filter_merged_matches(merged_matches)\n",
    "\n",
    "# Step 6: Concatenate favela_buildings with merged_matches\n",
    "final_dataframe = concatenate_dataframes(favela_buildings, filtered_merged_matches)\n",
    "\n",
    "# 'final_dataframe' now contains the concatenated GeoDataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab23697",
   "metadata": {},
   "source": [
    "total buildings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06f64087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16999"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataframe.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d01dbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typology\n",
       "house_low                  7938\n",
       "house_high                 6646\n",
       "sobrado                    1086\n",
       "apartment_building_low      901\n",
       "apartment_building_high     215\n",
       "villa                       205\n",
       "nan                           8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataframe['typology'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e95a6bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting original CRS\n",
    "final_dataframe=final_dataframe.set_crs('epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46e0c3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the selected matches to a new geopackage file\n",
    "final_dataframe.to_file(\"output/residential_typologies.gpkg\", driver=\"GPKG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
